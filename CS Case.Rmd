---
title: "CS Crystal Report"
author: "Milton Candela"
date: "3/6/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(randomForest)
```

Packages used:

* caret
* randomForest


## Data Preparation


```{r cars}
df <- read.csv('Automotive_2.csv', colClasses = c('character', 'character', 'factor', 'factor', 'character',
                                                  'factor', 'factor', 'character', 'factor', 'character',
                                                  'factor', 'numeric', 'character', 'factor', 'factor',
                                                  'factor', 'character', 'integer', 'character', 'character'))
# df <- na.omit(df)

# (dateCrawled) Data is not relevant, should be removed.
df <- df[, -grep('dateCrawled', colnames(df))]

# (name) Information could be extracted, but would be removed.
df <- df[, -grep('name', colnames(df))]

# (seller) Factor variable, 2 levels but 99% of samples are "privat", so column should be removed.
df <- df[, -grep('seller', colnames(df))]

# (offerType) Remove numeric values, 99% of samples are "Angebot", so column should be removed.
df <- df[, -grep('offerType', colnames(df))]

# (price) Outliers are considered 95%, so they should be removed.
df[,'price'] <- as.integer(df$price)

# A series of NAs are on every column
df <- df[!is.na(df$price), ]
df <- df[df$price < quantile(df$price, 0.95, na.rm = TRUE),]

# (abtest) Removing levels with 0 samples.
df[, 'abtest'] <- droplevels(df$abtest)

# (vehicleType) Removing levels with 0 samples.
# 8422 are blank samples (10.61 % of data).
df[, 'vehicleType'] <- droplevels(df$vehicleType)

# (yearOfRegistration) Remove characters, blank spaces and outliers.
df[,'yearOfRegistration'] <- as.integer(df$yearOfRegistration)
df <- df[(df$yearOfRegistration > 1900) & (df$yearOfRegistration < 2022),]

# (gearbox) Removing levels with 0 samples.
# 4519 are blank samples (5.69 % of data)
df[, 'gearbox'] <- droplevels(df$gearbox)

# (powerPs) Converting to numeric, maybe 0 was considered as a NA value as for the histogram.
df[, 'powerPS'] <- as.integer(df$powerPS)
df <- df[df$powerPS < quantile(df$powerPS, 0.95),]
hist(df$powerPS)

# Looking at the histogram, 0s might be NAs, so we then remove 0s
df <- df[df$powerPS != 0, ]
hist(df$powerPS)
# Now that histogram looks better! Now blank samples from "gearbox" passed from 4519 to 1454 and "vehicleType" from 8422 to 5017.

# (model) Too many levels, may not be useful.
summary(df$model)
df <- df[, -grep('model', colnames(df))]

# (kilometer) Histogram looks skewed to the right, may not be useful.
# df <- df[, -grep('kilometer', colnames(df))]

# (monthOfRegistration) Converting to integer, as outliers have been removed.
df[, 'monthOfRegistration'] <- as.integer(df$monthOfRegistration)

# (fuelType) Main classes are benizin and diesel, others could be removed.
df[, 'fuelType'] <- droplevels(df$fuelType)

# (brand) Too many levels, may not be useful.
df[, 'brand'] <- droplevels(df$brand)
# <- df[, -grep('brand', colnames(df))]

# (notRepairedDamage) Removing levels with 0 samples (dates).
# 10610 blank samples (16.02 % of data)
df[, 'notRepairedDamage'] <- droplevels(df$notRepairedDamage)

# (dateCreated) Not useful, should be removed.
df <- df[, -grep('dateCreated', colnames(df))]

# (nrOfPictures) All values are 0, should be removed.
df <- df[, -grep('nrOfPictures', colnames(df))]

# (postalCode) Not useful, should be removed.
df <- df[, -grep('postalCode', colnames(df))]

# (lastSeen) Used for our classification model (if NAs, then car was not sold yet)
encoding_class <- function(x){
     if (is.na(x)){
          0
     } else {
          1
     }
}
df[, 'sold'] <- sapply(as.Date(df$lastSeen), FUN = encoding_class)
df <- df[, -grep('lastSeen', colnames(df))]

df2 <- df
y <- df2[, 'sold']
df2 <- df2[, -grep('sold', colnames(df2))]
```

## Filling missing values

```{r pressure}
set.seed(1002)
missing_cat_cols <- c('gearbox', 'vehicleType', 'notRepairedDamage', 'fuelType')
full_cols <- colnames(df2)[!colnames(df2) %in% missing_cat_cols]

fill_missing <- function(df2, col_name){
     print(col_name)
     print(summary(df2[, col_name]))
     
     train_data <- df2[df2[,col_name]!='',c(full_cols, col_name)]
     train_data[, col_name] <- droplevels(train_data[, col_name])
     names(train_data)[names(train_data) == col_name] <- 'Class'
     #train_data <- downSample(x = train_data[, -grep(col_name, colnames(train_data))], y = train_data[, col_name])
     
     print(summary(train_data[, 'Class']))
     
     predict_data <- df2[df2[,col_name]=='',full_cols]
     model <- train(Class ~ ., data = train_data, method = 'rpart')
     
     df2[df2[, col_name]=='', col_name] <- predict(model, predict_data, type = 'raw')
     df2[, col_name] <- droplevels(df2[, col_name])
     
     print(summary(df2[, col_name]))
     
     df2
}

for (missing_col in missing_cat_cols){
     df2 <- fill_missing(df2, missing_col)
}

df3 <- df2
```

## Classification model

```{r }
set.seed(500)

df3 <- downSample(df3, as.factor(y), yname = 'sold')

trainIndex <- createDataPartition(df3$sold, p = 0.70, list = FALSE)
training <- df3[trainIndex,]
testing <- df3[-trainIndex,]

imp <- importance(randomForest(sold ~., data=training))
imp_cols <- names(imp[imp > 1000,])

training <- training[, c(imp_cols, 'sold')]
testing <- testing[, c(imp_cols, 'sold')]

write.csv(training, 'training.csv')
write.csv(testing, 'testing.csv')

set.seed(1000)

model <- train(sold ~ ., data = training, method = 'rpart')
pred <- predict(model, testing, type = 'raw')
print(confusionMatrix(pred, testing$sold))
```